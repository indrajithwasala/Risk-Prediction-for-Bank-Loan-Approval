{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdD3n6PI4xET"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "\n",
        "germanCredit = pd.read_csv(\"germancredit.csv\")\n",
        "germanCredit['installment'] = germanCredit['installment'].astype(object)\n",
        "germanCredit['residence'] = germanCredit['residence'].astype(object)\n",
        "germanCredit['cards'] = germanCredit['cards'].astype(object)\n",
        "germanCredit['liable'] = germanCredit['liable'].astype(object)\n",
        "\n",
        "############# a)\n",
        "# Separating qualitative and quantitative predictors\n",
        "qual = []\n",
        "quan = []\n",
        "\n",
        "for col in germanCredit.columns:\n",
        "    if germanCredit[col].dtype == 'object':  # Assuming object dtype represents factors\n",
        "        qual.append(col)\n",
        "    else:\n",
        "        quan.append(col)\n",
        "\n",
        "#remove default\n",
        "quan = quan[1:]\n",
        "\n",
        "data_qual = germanCredit[qual]\n",
        "data_quan = germanCredit[quan]\n",
        "\n",
        "# Your data and col/qual definitions here...\n",
        "\n",
        "num_qual_cols = len(qual)\n",
        "num_quan_cols = len(quan)\n",
        "\n",
        "# Determine the number of rows for barplots (4 columns per row)\n",
        "num_barplot_rows = (num_qual_cols + 3) // 4\n",
        "\n",
        "# Create a 4x3 grid for barplots\n",
        "plt.figure(figsize=(15, 5 * num_barplot_rows))\n",
        "for i, col in enumerate(qual):\n",
        "    if col != 'Default':\n",
        "        plt.subplot(num_barplot_rows, 4, i + 1)\n",
        "        sns.countplot(x=col, hue=\"Default\", data=germanCredit)\n",
        "        plt.xlabel(\"Default Status\")\n",
        "        plt.ylabel(col)\n",
        "        plt.title(f\"Barplot for {col}\")\n",
        "\n",
        "# Create a 1x3 grid for boxplots\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, col in enumerate(quan):\n",
        "    plt.subplot(1, num_quan_cols, i + 1)\n",
        "    sns.boxplot(x=\"Default\", y=col, data=germanCredit)\n",
        "    plt.xlabel(\"Default status\")\n",
        "    plt.ylabel(col)\n",
        "    plt.title(f\"Boxplot for {col}\")\n",
        "\n",
        "plt.tight_layout()  # Ensure proper spacing between subplots\n",
        "plt.show()\n",
        "\n",
        "#### significance of quantitatve predictor variables\n",
        "\n",
        "# Create an empty list to store p-values\n",
        "p_values = []\n",
        "\n",
        "# Iterate through the predictor variables\n",
        "for col in quan:\n",
        "    formula = f'Default ~ {col}'\n",
        "    model = smf.glm(formula=formula, data=germanCredit, family=sm.families.Binomial())\n",
        "    fit = model.fit()\n",
        "\n",
        "    # Extract the p-value for the variable\n",
        "    p_value = fit.pvalues[col]\n",
        "\n",
        "    # Print the p-value for the variable\n",
        "    print(f'P-Value for {col}: {p_value}')\n",
        "\n",
        "    # Append the p-value to the list\n",
        "    p_values.append(p_value)\n",
        "\n",
        "#### significance of qualitative predictor variables\n",
        "formula_intercept = 'Default ~ 1'\n",
        "model_intercept = smf.glm(formula=formula_intercept, data=germanCredit, family=sm.families.Binomial())\n",
        "fit_intercept = model_intercept.fit()\n",
        "\n",
        "for col in qual[1:]:\n",
        "  formula = f'Default ~ {col}'\n",
        "  model = smf.glm(formula=formula, data=germanCredit, family=sm.families.Binomial())\n",
        "  fit = model.fit()\n",
        "\n",
        "  lr_test = 2 * (fit.llf - fit_intercept.llf)\n",
        "  df = fit.df_model - fit_intercept.df_model\n",
        "  p_value = 1 - stats.chi2.cdf(lr_test, df)\n",
        "\n",
        "  # Print the LRT results\n",
        "  print(f'Summary for {col}:')\n",
        "  print(f\"LRT Statistic: {lr_test}\")\n",
        "  print(f\"Degrees of Freedom: {df}\")\n",
        "  print(f\"P-Value: {p_value}\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "############# b)\n",
        "\n",
        "# Initial formula with all variables\n",
        "formula = 'Default ~ checkingstatus1 + duration + history + purpose + amount + savings + employ + installment + status + others + residence + property + age + otherplans + housing + cards + job + liable + tele + foreign'\n",
        "model = smf.glm(formula=formula, data=germanCredit, family=sm.families.Binomial())\n",
        "fit = model.fit()\n",
        "\n",
        "# Create a list of variables to be removed\n",
        "variables_to_remove = ['employ', 'property','age', 'cards', 'job', 'liable']\n",
        "for variable in variables_to_remove:\n",
        "    # Remove the current variable from the formula\n",
        "    formula = formula.replace(f\" + {variable}\", \"\")\n",
        "    formula = formula.replace(f\" {variable} + \", \" + \")\n",
        "\n",
        "    # Create a new model and fit it\n",
        "    model = smf.glm(formula=formula, data=germanCredit, family=sm.families.Binomial())\n",
        "    new_fit = model.fit()\n",
        "\n",
        "    # Perform likelihood ratio test (LRT)\n",
        "    lr_test = 2 * (fit.llf - new_fit.llf)\n",
        "    df = fit.df_model - new_fit.df_model\n",
        "    p_value = 1 - stats.chi2.cdf(lr_test, df)\n",
        "\n",
        "    # Print the LRT results\n",
        "    print(f\"Removing variable {variable}:\")\n",
        "    print(f\"LRT Statistic: {lr_test}\")\n",
        "    print(f\"Degrees of Freedom: {df}\")\n",
        "    print(f\"P-Value: {p_value}\")\n",
        "    print(\"\\n\")\n",
        "    print(f\"AIC: {new_fit.aic}\")\n",
        "\n",
        "    # Update fit to the new_fit for the next iteration\n",
        "    fit = new_fit\n",
        "\n",
        "############# c)\n",
        "\n",
        "lr_prob = new_fit.predict(germanCredit)\n",
        "\n",
        "# Predict binary outcomes based on a threshold (0.5 in this case)\n",
        "lr_pred = (lr_prob >= 0.5).astype(int)\n",
        "\n",
        "# Calculate training error rate\n",
        "training_error_rate = 1 - (lr_pred == germanCredit['Default']).mean()\n",
        "print(f\"Training Error Rate: {training_error_rate:.3f}\")\n",
        "\n",
        "\n",
        "############################################################\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import KFold, LeaveOneOut, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "germanCredit = pd.read_csv(\"germancredit.csv\")\n",
        "germanCredit['installment'] = germanCredit['installment'].astype(object)\n",
        "germanCredit['residence'] = germanCredit['residence'].astype(object)\n",
        "germanCredit['cards'] = germanCredit['cards'].astype(object)\n",
        "germanCredit['liable'] = germanCredit['liable'].astype(object)\n",
        "\n",
        "X = germanCredit.loc[:, germanCredit.columns != 'Default']\n",
        "y = germanCredit['Default']\n",
        "\n",
        "####### part a)\n",
        "\n",
        "formula = 'Default ~ checkingstatus1 + duration + history + purpose + amount + savings + employ + installment + status + others + residence + property + age + otherplans + housing + cards + job + liable + tele + foreign'\n",
        "model = smf.glm(formula=formula, data=germanCredit, family=sm.families.Binomial())\n",
        "fit1 = model.fit()\n",
        "print(fit1.summary())\n",
        "\n",
        "lr_prob = fit1.predict(X)\n",
        "lr_pred = np.empty(lr_prob.shape, dtype=object)\n",
        "lr_pred[lr_prob<0.5] = 0\n",
        "lr_pred[lr_prob>=0.5] = 1\n",
        "\n",
        "## Training error rate\n",
        "np.mean(lr_pred != germanCredit['Default'])\n",
        "np.mean(lr_pred != y)\n",
        "\n",
        "confusion_matrix = pd.crosstab(germanCredit['Default'], lr_pred, rownames=['Actual'], colnames=['Predicted'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "# Calculate sensitivity (True Positive Rate)\n",
        "TP = confusion_matrix.iloc[1, 1]  # True Positives\n",
        "FN = confusion_matrix.iloc[1, 0]  # False Negatives\n",
        "sensitivity = TP / (TP + FN)\n",
        "\n",
        "# Calculate specificity\n",
        "TN = confusion_matrix.iloc[0, 0]  # True Negatives\n",
        "FP = confusion_matrix.iloc[0, 1]  # False Positives\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(f\"Sensitivity (True Positive Rate): {sensitivity:.3f}\")\n",
        "print(f\"Specificity: {specificity:.3f}\")\n",
        "\n",
        "###### part b)\n",
        "\n",
        "misClass_Error = np.zeros(len(germanCredit))\n",
        "for i in range(len(germanCredit)):\n",
        "    #dataTest = germanCredit.loc[i, :]\n",
        "    dataTest = germanCredit.loc[i:i, :].copy()\n",
        "    dataTrain = germanCredit.drop(i, axis=0)\n",
        "\n",
        "    formula = 'Default ~ checkingstatus1 + duration + history + purpose + amount + savings + employ + installment + status + others + residence + property + age + otherplans + housing + cards + job + liable + tele + foreign'\n",
        "    model = smf.glm(formula = formula, data = dataTrain, family=sm.families.Binomial())\n",
        "    fit = model.fit()\n",
        "\n",
        "    lr_prob = fit.predict(dataTest)\n",
        "    lr_pred = np.empty(lr_prob.shape, dtype=object)\n",
        "    lr_pred[lr_prob<0.5] = 0\n",
        "    lr_pred[lr_prob>=0.5] = 1\n",
        "\n",
        "    misClass_Error[i] = np.mean(lr_pred != dataTest['Default'])\n",
        "\n",
        "print('Training error: = (%.3f)' % np.mean(misClass_Error))\n",
        "\n",
        "###### part c)\n",
        "\n",
        "preds, scores = [], []\n",
        "kfold = KFold(n_splits=germanCredit.shape[0])\n",
        "\n",
        "for train_idx, test_idx in kfold.split(germanCredit):\n",
        "    X_train, X_test = X.iloc[train_idx,:], X.iloc[test_idx,:]\n",
        "    y_test = y[test_idx]\n",
        "    formula = 'Default ~ checkingstatus1 + duration + history + purpose + amount + savings + employ + installment + status + others + residence + property + age + otherplans + housing + cards + job + liable + tele + foreign'\n",
        "    model = smf.glm(formula = formula, data = germanCredit.iloc[train_idx,:], family=sm.families.Binomial()).fit()\n",
        "    scores.append(model.predict(X_test))\n",
        "    preds.append(1* (model.predict(X_test)>=0.5) == y_test)\n",
        "\n",
        "print('Training error: = (%.4f)' % (1- np.mean(np.array(preds))))\n",
        "\n",
        "######### part d)\n",
        "\n",
        "# Create an instance of LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "# Define the list of categorical columns to be encoded\n",
        "categorical_columns = ['checkingstatus1', 'history', 'purpose', 'savings', 'employ', 'installment',\n",
        "                       'status', 'others','residence', 'property', 'otherplans','housing','cards', 'job','liable', 'tele', 'foreign']\n",
        "# Apply label encoding to each categorical column\n",
        "for column in categorical_columns:\n",
        "  germanCredit[column] = label_encoder.fit_transform(germanCredit[column])\n",
        "\n",
        "X = germanCredit.loc[:, germanCredit.columns != 'Default']\n",
        "y = germanCredit['Default']\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "lda.fit(X, y)\n",
        "\n",
        "ldapred_train = lda.predict(X)\n",
        "\n",
        "misclassification_train = 1 - accuracy_score(y, ldapred_train)\n",
        "print(f\"\\nTraining Misclassification Rate: {misclassification_train:.3f}\")\n",
        "\n",
        "conf_mat_train = pd.crosstab(ldapred_train, y, rownames = ['predict'], colnames = ['train'])\n",
        "print(\"\\n Confusion Matrix for train data \\n\", conf_mat_train)\n",
        "\n",
        "# Calculate sensitivity (True Positive Rate)\n",
        "TP = conf_mat_train.iloc[1, 1]  # True Positives\n",
        "FN = conf_mat_train.iloc[1, 0]  # False Negatives\n",
        "sensitivity = TP / (TP + FN)\n",
        "\n",
        "# Calculate specificity\n",
        "TN = conf_mat_train.iloc[0, 0]  # True Negatives\n",
        "FP = conf_mat_train.iloc[0, 1]  # False Positives\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(f\"Sensitivity (True Positive Rate): {sensitivity:.3f}\")\n",
        "print(f\"Specificity: {specificity:.3f}\")\n",
        "\n",
        "#calculate Training error using LOOCV\n",
        "lda_score = cross_val_score(estimator=lda, X=X, y=y, cv=loo)\n",
        "print('Training error: = (%.3f)' % (1- np.mean(lda_score)))\n",
        "\n",
        "probs = lda.predict_proba(X)\n",
        "probs_one = [i[1] for i in probs]\n",
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y, probs_one)\n",
        "sns.lineplot(x = fpr, y = tpr).set(xlabel = \"FPR\", ylabel = \"TPR\", title = \"ROC Curve LDA\")\n",
        "\n",
        "\n",
        "####### part e)\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "qda.fit(X, y)\n",
        "\n",
        "qdapred_train = qda.predict(X)\n",
        "\n",
        "misclassification_train = 1 - accuracy_score(y, qdapred_train)\n",
        "print(f\"\\nTraining Misclassification Rate: {misclassification_train:.3f}\")\n",
        "\n",
        "conf_mat_train = pd.crosstab(qdapred_train, y, rownames = ['predict'], colnames = ['train'])\n",
        "print(\"\\n Confusion Matrix for train data \\n\", conf_mat_train)\n",
        "\n",
        "# Calculate sensitivity (True Positive Rate)\n",
        "TP = conf_mat_train.iloc[1, 1]  # True Positives\n",
        "FN = conf_mat_train.iloc[1, 0]  # False Negatives\n",
        "sensitivity = TP / (TP + FN)\n",
        "\n",
        "# Calculate specificity\n",
        "TN = conf_mat_train.iloc[0, 0]  # True Negatives\n",
        "FP = conf_mat_train.iloc[0, 1]  # False Positives\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(f\"Sensitivity (True Positive Rate): {sensitivity:.3f}\")\n",
        "print(f\"Specificity: {specificity:.3f}\")\n",
        "\n",
        "#calculate Training error using LOOCV\n",
        "qda_score = cross_val_score(estimator=qda, X=X, y=y, cv=loo)\n",
        "print('Training error: = (%.3f)' % (1- np.mean(qda_score)))\n",
        "\n",
        "probs = qda.predict_proba(X)\n",
        "probs_one = [i[1] for i in probs]\n",
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y, probs_one)\n",
        "sns.lineplot(x = fpr, y = tpr).set(xlabel = \"FPR\", ylabel = \"TPR\", title = \"ROC Curve QDA\")\n",
        "\n",
        "######### parts f)\n",
        "\n",
        "knn2 = KNeighborsClassifier()\n",
        "param_grid = {'n_neighbors': np.arange(1, 10)}\n",
        "knn_gscv = GridSearchCV(knn2, param_grid, cv=loo)\n",
        "knn_gscv.fit(X, y)\n",
        "print('K that minimize test error: ', knn_gscv.best_params_)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=77)\n",
        "knn.fit(X, y)\n",
        "\n",
        "knnpred_train = knn.predict(X)\n",
        "\n",
        "misclassification_train = 1 - accuracy_score(y, knnpred_train)\n",
        "print(f\"\\nTraining Misclassification Rate: {misclassification_train:.3f}\")\n",
        "\n",
        "conf_mat_train = pd.crosstab(knnpred_train, y, rownames = ['predict'], colnames = ['train'])\n",
        "print(\"\\n Confusion Matrix for train data \\n\", conf_mat_train)\n",
        "\n",
        "# Calculate sensitivity (True Positive Rate)\n",
        "TP = conf_mat_train.iloc[1, 1]  # True Positives\n",
        "FN = conf_mat_train.iloc[1, 0]  # False Negatives\n",
        "sensitivity = TP / (TP + FN)\n",
        "\n",
        "# Calculate specificity\n",
        "TN = conf_mat_train.iloc[0, 0]  # True Negatives\n",
        "FP = conf_mat_train.iloc[0, 1]  # False Positives\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(f\"Sensitivity (True Positive Rate): {sensitivity:.3f}\")\n",
        "print(f\"Specificity: {specificity:.3f}\")\n",
        "\n",
        "#calculate training error using LOOCV\n",
        "print('\\n Training error: = (%.4f)' % (1 - knn_gscv.best_score_))\n",
        "\n",
        "probs = knn.predict_proba(X)\n",
        "probs_one = [i[1] for i in probs]\n",
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y, probs_one)\n",
        "sns.lineplot(x = fpr, y = tpr).set(xlabel = \"FPR\", ylabel = \"TPR\", title = \"ROC Curve KNN\")\n",
        "\n",
        "######### parts g)\n",
        "\n",
        "germanCredit = pd.read_csv(\"germancredit.csv\")\n",
        "germanCredit['installment'] = germanCredit['installment'].astype(object)\n",
        "germanCredit['residence'] = germanCredit['residence'].astype(object)\n",
        "germanCredit['cards'] = germanCredit['cards'].astype(object)\n",
        "germanCredit['liable'] = germanCredit['liable'].astype(object)\n",
        "\n",
        "X = germanCredit.loc[:, germanCredit.columns != 'Default']\n",
        "y = germanCredit['Default']\n",
        "\n",
        "formula = 'Default ~ checkingstatus1 + duration + history + purpose + amount + savings + installment + status + others + residence + otherplans + housing + tele + foreign'\n",
        "model = smf.glm(formula=formula, data=germanCredit, family=sm.families.Binomial())\n",
        "red_fit = model.fit()\n",
        "\n",
        "lr_prob = red_fit.predict(X)\n",
        "lr_pred = np.empty(lr_prob.shape, dtype=object)\n",
        "lr_pred[lr_prob<0.5] = 0\n",
        "lr_pred[lr_prob>=0.5] = 1\n",
        "\n",
        "## Training error rate\n",
        "np.mean(lr_pred != germanCredit['Default'])\n",
        "np.mean(lr_pred != y)\n",
        "\n",
        "confusion_matrix = pd.crosstab(germanCredit['Default'], lr_pred, rownames=['Actual'], colnames=['Predicted'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "# Calculate sensitivity (True Positive Rate)\n",
        "TP = confusion_matrix.iloc[1, 1]  # True Positives\n",
        "FN = confusion_matrix.iloc[1, 0]  # False Negatives\n",
        "sensitivity = TP / (TP + FN)\n",
        "\n",
        "# Calculate specificity\n",
        "TN = confusion_matrix.iloc[0, 0]  # True Negatives\n",
        "FP = confusion_matrix.iloc[0, 1]  # False Positives\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(f\"Sensitivity (True Positive Rate): {sensitivity:.3f}\")\n",
        "print(f\"Specificity: {specificity:.3f}\")\n",
        "\n",
        "misClass_Error = np.zeros(len(germanCredit))\n",
        "for i in range(len(germanCredit)):\n",
        "    #dataTest = germanCredit.loc[i, :]\n",
        "    dataTest = germanCredit.loc[i:i, :].copy()\n",
        "    dataTrain = germanCredit.drop(i, axis=0)\n",
        "\n",
        "    formula = 'Default ~ checkingstatus1 + duration + history + purpose + amount + savings + installment + status + others + residence + otherplans + housing + tele + foreign'\n",
        "    model = smf.glm(formula = formula, data = dataTrain, family=sm.families.Binomial())\n",
        "    fit = model.fit()\n",
        "\n",
        "    lr_prob = fit.predict(dataTest)\n",
        "    lr_pred = np.empty(lr_prob.shape, dtype=object)\n",
        "    lr_pred[lr_prob<0.5] = 0\n",
        "    lr_pred[lr_prob>=0.5] = 1\n",
        "\n",
        "    misClass_Error[i] = np.mean(lr_pred != dataTest['Default'])\n",
        "\n",
        "######################################################\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold, LeaveOneOut, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "germanCredit = pd.read_csv(\"germancredit.csv\")\n",
        "cat_preds = [\"checkingstatus1\", \"history\", \"purpose\", \"savings\", \"employ\",\n",
        "\"status\", \"others\", \"property\", \"otherplans\", \"housing\",\n",
        "\"job\", \"tele\", \"foreign\", \"liable\"]\n",
        "# Encode categorical predictors\n",
        "germanCredit = pd.get_dummies(data = germanCredit, columns = cat_preds, drop_first = True)\n",
        "\n",
        "X = germanCredit.loc[:, germanCredit.columns != 'Default']\n",
        "y = germanCredit['Default']\n",
        "\n",
        "### a) logistic regression model using all predictors\n",
        "\n",
        "# Standardize features (important for logistic regression)\n",
        "X_scaled = X.values\n",
        "\n",
        "# Create a logistic regression model\n",
        "logistic_model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# Create Leave-One-Out cross-validation\n",
        "loocv = LeaveOneOut()\n",
        "\n",
        "# Initialize variables to store accuracy scores\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform LOOCV\n",
        "for train_index, test_index in loocv.split(X_scaled):\n",
        "X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# Fit the model on the training data\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "# Calculate and store accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy_scores.append(accuracy)\n",
        "\n",
        "# Calculate the mean accuracy over all LOOCV iterations\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "\n",
        "print(\"Mean Accuracy using LOOCV:\", mean_accuracy)\n",
        "\n",
        "\n",
        "### (b), (c) Fit Ridge and Lasso logistic regression model\n",
        "\n",
        "# Create a logistic regression model\n",
        "logistic_model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# Define a grid of hyperparameters to search\n",
        "param_grid_l1 = {\n",
        "\t'penalty': ['l1'],  # L1 (Lasso) regularization\n",
        "\t'C': np.logspace(-4, 1, 5)  # A range of regularization strengths\n",
        "}\n",
        "\n",
        "param_grid_l2 = {\n",
        "\t'penalty': ['l2'],  # L2 (Ridge) regularization\n",
        "\t'C': np.logspace(-4, 4, 10)  # A range of regularization strengths\n",
        "}\n",
        "\n",
        "# Create Leave-One-Out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Create GridSearchCV objects for L1 and L2\n",
        "grid_search_l1 = GridSearchCV(logistic_model, param_grid_l1, cv=loo, scoring='accuracy')\n",
        "grid_search_l2 = GridSearchCV(logistic_model, param_grid_l2, cv=loo, scoring='accuracy')\n",
        "\n",
        "# Fit the models to the data to perform grid search\n",
        "grid_search_l1.fit(X, y)\n",
        "grid_search_l2.fit(X, y)\n",
        "\n",
        "# Get the best parameters and best scores for L1 and L2\n",
        "best_params_l1 = grid_search_l1.best_params_\n",
        "best_score_l1 = grid_search_l1.best_score_\n",
        "\n",
        "best_params_l2 = grid_search_l2.best_params_\n",
        "best_score_l2 = grid_search_l2.best_score_\n",
        "\n",
        "print(\"Best Parameters for L1:\", best_params_l1)\n",
        "print(\"Best Score for L1:\", best_score_l1)\n",
        "\n",
        "print(\"Best Parameters for L2:\", best_params_l2)\n",
        "print(\"Best Score for L2:\", best_score_l2)"
      ]
    }
  ]
}